{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "from copy import deepcopy\n",
    "import networkx as nx\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data format:\n",
    "\n",
    "    Id: Product id (number 0, ..., 548551)\n",
    "\n",
    "    ASIN: Amazon Standard Identification Number\n",
    "\n",
    "    title: Name/title of the product\n",
    "\n",
    "    group: Product group (Book, DVD, Video or Music)\n",
    "\n",
    "    salesrank: Amazon Salesrank\n",
    "\n",
    "    similar: ASINs of co-purchased products (people who buy X also buy Y)\n",
    "\n",
    "    categories: Location in product category hierarchy to which the product belongs (separated by |, category id in [])\n",
    "\n",
    "    reviews: Product review information: time, user id, rating, total number of votes on the review, total number of helpfulness votes (how many people found the review to be helpful)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaner:\n",
    "    \"\"\" DataCleaner object maintains state for a single document.\n",
    "    \n",
    "    Author: Miguel Agueda-Cabral.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.total_items = None  # Total number of items expected.\n",
    "        self.state = {  # Temporary document to store each product before saving to list.\n",
    "            \"Id\": None,\n",
    "            \"ASIN\": None,\n",
    "            \"title\": None,\n",
    "            \"group\": None,\n",
    "            \"salesrank\": None,\n",
    "            \"similar\": None,\n",
    "            \"categories\": None,\n",
    "            \"reviews\": None\n",
    "        }\n",
    "        \n",
    "        self.product_list = []  # List for holding all products. \n",
    "    \n",
    "    def reset_state(self):\n",
    "        \"\"\" Reset internal state document for incoming document.\n",
    "        \n",
    "        Author: Miguel Agueda-Cabral.\"\"\"\n",
    "        \n",
    "#         keys = list(self.state.keys())  # Retrieve keys from dictionary.\n",
    "#         for key in keys:  # Loop over each key.\n",
    "#             self.state[key] = None  # Set value for key to None.\n",
    "\n",
    "        self.state = self.state.fromkeys(self.state, None)  # Alternatively, use builtin method.\n",
    "            \n",
    "    def process_line(self, line):\n",
    "        \"\"\" Process incoming lines.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            line: List of text read in from source file.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "            None.\n",
    "        \n",
    "        Author: Miguel Agueda-Cabral.\"\"\"\n",
    "        \n",
    "        if len(line) == 0:  # This is an empty line. Nothing else to do. Return to caller.\n",
    "            return\n",
    "        \n",
    "        # The line is not empty, continue on to processing. \n",
    "        line[0] = line[0].strip(' ')  # Remove empty spaces.\n",
    "        if \"Total items\" == line[0]:\n",
    "            self.total_items = line[1]  # Get total number of products from list.\n",
    "            \n",
    "        elif \"Id\" == line[0]:\n",
    "            if self.state[\"Id\"] != None:  # If the state is filled out...\n",
    "                self.product_list.append(deepcopy(self.state))  # Make a deep copy and add to list.\n",
    "                self.reset_state()  # Then reset the state before adding newly found ID. \n",
    "            \n",
    "            self.state[\"Id\"] = int(line[1])  # Update newly found ID.\n",
    "        \n",
    "        elif \"ASIN\" == line[0]:\n",
    "            self.state[\"ASIN\"] = line[1].strip()  # Update ASIN number from list.\n",
    "        \n",
    "        elif \"title\" in line[0]:          \n",
    "            if len(line) > 2:  # The title got broken up during parsing.\n",
    "                for piece in line[2:]:  # Loop over each section of the title.\n",
    "                    line[1] = F\"{line[1]}: {piece}\"  # Put title back together, piece-by-piece.\n",
    "                \n",
    "            self.state[\"title\"] = line[1]  # Update title from list.\n",
    "        \n",
    "        elif \"group\" == line[0]:\n",
    "            self.state[\"group\"] = line[1]  # Update group from list.\n",
    "        \n",
    "        elif \"salesrank\" == line[0]:\n",
    "            self.state[\"salesrank\"] = int(line[1])  # Update salesrank from list.\n",
    "        \n",
    "        elif \"similar\" == line[0]:\n",
    "            line = ' '.join(line[1].split()).split(' ')  # Break up string of products into list of products.\n",
    "            similar = []  # Initialize list for holding similar products. \n",
    "            num_similar = int(line[0])  # Retrieve the number of similar items. \n",
    "            for i in range(num_similar):  # Loop over range of similar items.\n",
    "                similar.append(line[i+1])  # Append each similar item to list of items.\n",
    "            \n",
    "            self.state[\"similar\"] = similar  # Update list of similar items.\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9223372036854775807\n"
     ]
    }
   ],
   "source": [
    "\"\"\"From https://www.semicolonworld.com/question/57946/csv-error-field-larger-than-field-limit-131072\n",
    "\"\"\"\n",
    "import sys\n",
    "import csv\n",
    "maxInt = sys.maxsize\n",
    "while True:\n",
    "    # decrease the maxInt value by factor 10 \n",
    "    # as long as the OverflowError occurs.\n",
    "\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "        print(maxInt)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"amazon-meta.txt\"\n",
    "DC = DataCleaner()\n",
    "csv.field_size_limit(922337203)\n",
    "\n",
    "with open(path, mode='r', newline=\"\\n\", encoding=\"utf8\") as file:  # Open source file.\n",
    "    lines = csv.reader(file, delimiter=\":\")  # Utilize CSV to separate values at each colon (:). \n",
    "        \n",
    "    for row in lines:\n",
    "        DC.process_line(row)  # Process each row using DataCleaner object.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: 548552 items and got 547333 items\n"
     ]
    }
   ],
   "source": [
    "print(F\"Expected:{DC.total_items} items and got {len(DC.product_list)} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a network using the data saved in DC.product_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 547333\n",
      "Number of edges: 983479\n",
      "Average degree:   3.5937\n"
     ]
    }
   ],
   "source": [
    "# Each node will be an ASIN and will link to other ASINs in its 'similar' list\n",
    "G = nx.Graph()\n",
    "\n",
    "# 1. Create the nodes for G\n",
    "visitedASINs = {} # Will hold all the nodes we add to G\n",
    "for product in DC.product_list:\n",
    "    node = product['ASIN'].strip() # Strip because some ASINs have a space at the beginning\n",
    "    G.add_node(node)\n",
    "    visitedASINs[node] = True # Takes note that we visited this ASIN\n",
    "\n",
    "# 2. Create the edges for G\n",
    "for product in DC.product_list:\n",
    "    \n",
    "    node = product['ASIN'].strip() \n",
    "    \n",
    "    if product['similar'] is not None: # If its 'similar' list is not empty\n",
    "        \n",
    "        # Ensures that there are no hidden spaces in the strings inside product['similar'] array\n",
    "        similar = [unlinked_node.strip() for unlinked_node in product['similar'] ]\n",
    "        \n",
    "        # For each unlinked node in the 'similar' array, link it to the current node, provided its in the 'visited' hashmap\n",
    "        for unlinked_node in similar:\n",
    "            if unlinked_node in visitedASINs:\n",
    "                G.add_edge(node, unlinked_node)\n",
    "            \n",
    "\n",
    "print(nx.info(G))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the network communities and analysis of their homogeneity with respect to product categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import community as community_louvain\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "partition = community_louvain.best_partition(G)  # Note: Expensive to compute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of communities detected:  187501\n"
     ]
    }
   ],
   "source": [
    "num_communities = len(set(partition.values()))\n",
    "print(\"Number of communities detected: \", num_communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_results = nx.pagerank(G)  # Get results of pagerank. Note: Expensive to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B00008LDNZ 0.00026912459377108854\n",
      "0890420254 0.00010000372803388047\n",
      "1557987912 9.895695905994515e-05\n",
      "0803606540 8.168190895099388e-05\n",
      "0875163238 7.979448268801228e-05\n",
      "096290497X 6.512017633226696e-05\n",
      "0130336297 6.353979315856513e-05\n",
      "0486291138 6.125708373637227e-05\n",
      "0486280861 6.10490026208551e-05\n",
      "0192833723 5.3007681877521416e-05\n",
      "1.  Laura\n",
      "2.  Diagnostic and Statistical Manual of Mental Disorders DSM-IV-TR (Text Revision) (Diagnostic and Statistical Manual of Mental Disorders)\n",
      "3.  Publication Manual of the American Psychological Association, Fifth Edition\n",
      "4.  Taber's Cyclopedic Medical Dictionary -Thumb-Indexed Version\n",
      "5.  It Works\n",
      "6.  Discerning of Spirits\n",
      "7.  Marketing Management\n",
      "8.  1001 Most Useful Spanish Words (Beginners' Guides)\n",
      "9.  Easy Spanish Phrase Book:  Over 770 Basic Phrases for Everyday Use\n",
      "10.  Confessions (Oxford World's Classics)\n"
     ]
    }
   ],
   "source": [
    "top_ten = sorted(pr_results, key=pr_results.get, reverse=True)[:10]\n",
    "\n",
    "for asin in top_ten:\n",
    "    print(asin, pr_results[asin])  # Analyze output, ensure decrementing order.\n",
    "\n",
    "for i, asin in enumerate(top_ten):\n",
    "#     print(asin, i)\n",
    "    for document in DC.product_list:\n",
    "#         print(document)\n",
    "#         input()\n",
    "        if document['ASIN'].strip() == asin.strip():\n",
    "        \n",
    "            print(F\"{i+1}. {document['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
