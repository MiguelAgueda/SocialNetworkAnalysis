{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "from copy import deepcopy\n",
    "import networkx as nx\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data format:\n",
    "\n",
    "    Id: Product id (number 0, ..., 548551)\n",
    "\n",
    "    ASIN: Amazon Standard Identification Number\n",
    "\n",
    "    title: Name/title of the product\n",
    "\n",
    "    group: Product group (Book, DVD, Video or Music)\n",
    "\n",
    "    salesrank: Amazon Salesrank\n",
    "\n",
    "    similar: ASINs of co-purchased products (people who buy X also buy Y)\n",
    "\n",
    "    categories: Location in product category hierarchy to which the product belongs (separated by |, category id in [])\n",
    "\n",
    "    reviews: Product review information: time, user id, rating, total number of votes on the review, total number of helpfulness votes (how many people found the review to be helpful)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaner:\n",
    "    \"\"\" DataCleaner object maintains state for a single document.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.init_flag = False  # Cleaner has not been initialized.\n",
    "        self.total_items = None\n",
    "        self.state = {\n",
    "            \"Id\": None,\n",
    "            \"ASIN\": None,\n",
    "            \"title\": None,\n",
    "            \"group\": None,\n",
    "            \"salesrank\": None,\n",
    "            \"similar\": None,\n",
    "            \"categories\": None,\n",
    "            \"reviews\": None\n",
    "        }\n",
    "        \n",
    "        self.product_list = []\n",
    "    \n",
    "    def reset_state(self):\n",
    "        keys = list(self.state.keys())\n",
    "        for key in keys:\n",
    "            self.state[key] = None\n",
    "            \n",
    "    def process_line(self, line):\n",
    "        if len(line) == 0:\n",
    "            return\n",
    "        \n",
    "        line[0] = line[0].strip(' ')\n",
    "        if \"Total items\" == line[0]:\n",
    "            self.total_items = line[1]\n",
    "            \n",
    "        elif \"Id\" == line[0]:\n",
    "            if self.state[\"Id\"] != None:\n",
    "                self.product_list.append(deepcopy(self.state))\n",
    "                self.reset_state()\n",
    "            \n",
    "            self.state[\"Id\"] = int(line[1])\n",
    "        \n",
    "        elif \"ASIN\" == line[0]:\n",
    "            self.state[\"ASIN\"] = line[1]\n",
    "        \n",
    "        elif \"title\" in line[0]:          \n",
    "            if len(line) > 2:  # The title got broken up during parsing.\n",
    "                for piece in line[2:]:\n",
    "                    line[1] = F\"{line[1]}: {piece}\"  # Put title back together.\n",
    "                \n",
    "            self.state[\"title\"] = line[1]\n",
    "#             print(F\"Title: {line[1]}\")\n",
    "        \n",
    "        elif \"group\" == line[0]:\n",
    "            self.state[\"group\"] = line[1]\n",
    "        \n",
    "        elif \"salesrank\" == line[0]:\n",
    "            self.state[\"salesrank\"] = int(line[1])\n",
    "        \n",
    "        elif \"similar\" == line[0]:\n",
    "            line = ' '.join(line[1].split()).split(' ')\n",
    "            similar = []\n",
    "            num_similar = int(line[0])\n",
    "            for i in range(num_similar):\n",
    "                similar.append(line[i+1])\n",
    "            \n",
    "            self.state[\"similar\"] = similar\n",
    "#         print(self.state)\n",
    " \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9223372036854775807\n"
     ]
    }
   ],
   "source": [
    "\"\"\"From https://www.semicolonworld.com/question/57946/csv-error-field-larger-than-field-limit-131072\n",
    "\"\"\"\n",
    "import sys\n",
    "import csv\n",
    "maxInt = sys.maxsize\n",
    "while True:\n",
    "    # decrease the maxInt value by factor 10 \n",
    "    # as long as the OverflowError occurs.\n",
    "\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "        print(maxInt)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Id': 0, 'ASIN': ' 0771044445', 'title': None, 'group': None, 'salesrank': None, 'similar': None, 'categories': None, 'reviews': None}, {'Id': 1, 'ASIN': ' 0827229534', 'title': ' Patterns of Preaching:  A Sermon Sampler', 'group': ' Book', 'salesrank': 396585, 'similar': ['0804215715', '156101074X', '0687023955', '0687074231', '082721619X'], 'categories': None, 'reviews': None}]\n"
     ]
    }
   ],
   "source": [
    "path = \"amazon-meta.txt\"\n",
    "DC = DataCleaner()\n",
    "csv.field_size_limit(922337203)\n",
    "\n",
    "with open(path, mode='r', newline=\"\\n\", encoding=\"utf8\") as file:\n",
    "    reader = csv.reader(file, delimiter=\":\")\n",
    "    for row in reader:\n",
    "        DC.process_line(row)\n",
    "    \n",
    "print(DC.product_list[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a network using the data saved in DC.product_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 547333\n",
      "Number of edges: 983479\n",
      "Average degree:   3.5937\n"
     ]
    }
   ],
   "source": [
    "# Each node will be an ASIN and will link to other ASINs in its 'similar' list\n",
    "G = nx.Graph()\n",
    "\n",
    "# 1. Create the nodes for G\n",
    "visitedASINs = {} # Will hold all the nodes we add to G\n",
    "for product in DC.product_list:\n",
    "    node = product['ASIN'].strip() # Strip because some ASINs have a space at the beginning\n",
    "    G.add_node(node)\n",
    "    visitedASINs[node] = True # Takes note that we visited this ASIN\n",
    "\n",
    "# 2. Create the edges for G\n",
    "for product in DC.product_list:\n",
    "    \n",
    "    node = product['ASIN'].strip() \n",
    "    \n",
    "    if product['similar'] is not None: # If its 'similar' list is not empty\n",
    "        \n",
    "        # Ensures that there are no hidden spaces in the strings inside product['similar'] array\n",
    "        similar = [unlinked_node.strip() for unlinked_node in product['similar'] ]\n",
    "        \n",
    "        # For each unlinked node in the 'similar' array, link it to the current node, provided its in the 'visited' hashmap\n",
    "        for unlinked_node in similar:\n",
    "            if unlinked_node in visitedASINs:\n",
    "                G.add_edge(node, unlinked_node)\n",
    "            \n",
    "\n",
    "print(nx.info(G))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the network communities and analysis of their homogeneity with respect to product categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
